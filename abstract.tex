% 
The validation of ground motion synthetics has received increased attention over the last few years due to the advances in physics-based deterministic and hybrid simulation methods. Unlike for low frequency simulations $(f \le 0.5 Hz)$, for which it has become reasonable to expect a good match between synthetics and data, in the case of high-frequency simulations $(1 Hz \le f)$ it is not possible to match results on a wiggle-by-wiggle basis. This is mostly due to the various complexities and uncertainties involved in earthquake ground motion modeling. Therefore, in order to compare synthetics with data we turn to different time series metrics, which are used as a means to characterize how the synthetics match the data on qualitative and statistical sense. In general, these metrics provide GOF scores that measure the level of similarity in the time and frequency domains. It is common for these scores to be scaled from 0 to 10, with 10 representing a perfect match. Although using individual metrics for particular applications is considered more adequate, there is no consensus or a unified method to classify the comparison between a set of synthetic and recorded seismograms when the various metrics offer different scores. We study the relationship among these metrics through 
semi-supervised and supervised learning approaches in order to labeling and classifying data, respectively. In particular we use constrained \kmeans{} clustering method, in which we define 4 hypothetical stations with scores 3, 5, 7, and 9 for all metrics. We put these stations in the category of cannot-link constraints. We generate the dataset through the validation of the results from a deterministic (physics-based) ground motion simulation for a moderate magnitude earthquake in the greater Los Angeles basin using three velocity models. The maximum frequency of the simulation is 4 Hz. The dataset involves over 300 stations and 11 metrics, or features, as they are understood in the machine learning lingo, where the metrics form a multi-dimensional space. We address the high-dimensional feature effects with a subspace-clustering analysis using 2,3, and 4 dimensional spaces. We label the dataset in each subspace as poor, fair, good, and excellent, where, hypothetical stations with score of 3,5,7, and 9 belongs them, respectively. We assign the final label based on the mode of subspaces for dataset.  Once the dataset has been labeled, we develop two decision trees using C5.0 algorithm to develop two prediction models to classify a simulation in four groups (poor, fair, good, and excellent) based on a reduced number of metrics. We address the unbalanced dataset issue through oversampling method and analyze the precision, recall and F1-score of the classifiers. The prediction models represent a simple, yet effective model to accurately classify the accuracy of the simulation process based on application-independent approach.







