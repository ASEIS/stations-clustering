% 
It has become common practice to validate ground motion simulation based on a variety of time- and frequency-domain metrics known in seismology and engineering and scaled to quantify the level of agreement between synthetics and data or other reference solutions. There is, however, no agreement about the importance or weight that it ought to be given to each individual metric. This leads to their selection often being subjective, either based on intended applications or personal preferences. In turn, this makes it difficult for simulators to identify modeling improvement needs, which could be easier if they could focused on a reduced number of alternative metrics. We present an analysis of ground motion validation metrics using semi-supervised and supervised learning techniques used to label and classify  goodness-of-fit (GOF) results, with the objective prioritizing and narrowing the choice of metrics available and commonly used in ground motion simulation validation. In particular, we study the relationships that exist between eleven different metrics when understood as part of a multi-dimensional space using a constrained \kmeans{} method. We conduct a subspace clustering analysis to address the high-dimensional effects and this allows us to label the results from a large validation dataset into four categories (poor, fair, good, and excellent). We then develop two decision trees using a C5.0 algorithm. These decision trees help narrow the number of metrics leading to a validation prediction into the four categories. These decision trees can be understood as rapid predictors of the quality of a simulation, or as a data-informed classifiers that can help prioritize validation metrics. Our analysis indicates that among the eleven metrics considered here, the acceleration response spectra and total energy of velocity are the most dominant metrics ones, followed by the peak ground response in terms of velocity and acceleration.

% OLD NAEEM VERSION
% 
% The validation of ground motion synthetics has received increased attention over the last few years due to the advances in physics-based deterministic and hybrid simulation methods. Unlike for low frequency simulations $(f \le 0.5 Hz)$, for which it has become reasonable to expect a good match between synthetics and data, in the case of high-frequency simulations $(1 Hz \le f)$ it is not possible to match results on a wiggle-by-wiggle basis. This is mostly due to the various complexities and uncertainties involved in earthquake ground motion modeling. Therefore, in order to compare synthetics with data we turn to different time series metrics, which are used as means to characterize how the synthetics match the data on qualitative and statistical sense. In general, these metrics provide GOF scores that measure the level of similarity in the time and frequency domains. It is common for these scores to be scaled from 0 to 10, with 10 representing a perfect match. Although using individual metrics for particular applications is considered more adequate, there is no consensus or a unified method to classify the comparison between a set of synthetic and recorded seismograms when the various metrics offer different scores. We study the relationship among these metrics through semi-supervised and supervised learning approaches in order to labeling and classifying data, respectively. In particular, we use constrained \kmeans{} clustering method, in which we define 4 hypothetical stations with scores 3, 5, 7, and 9 for all metrics. We put these stations in the category of cannot-link constraints. We generate the dataset through the validation of the results from a deterministic (physics-based) ground motion simulation for a moderate magnitude earthquake in the greater Los Angeles basin using three velocity models. The maximum frequency of the simulation is 4 Hz. The dataset involves over 300 stations and 11 metrics, or features, as they are understood in the machine learning lingo, where the metrics form a multi-dimensional space. We address the high-dimensional feature effects with a subspace-clustering analysis using 2,3, and 4 dimensional spaces. We label the dataset in each subspace as poor, fair, good, and excellent, where, hypothetical stations with score of 3,5,7, and 9 belong them, respectively. We assign the final label based on the mode of subspaces for each station.  Once the dataset has been labeled, we develop two decision trees using C5.0 algorithm as prediction models to classify a simulation in four groups (poor, fair, good, and excellent) based on a reduced number of metrics. We address the unbalanced dataset issue through oversampling method and analyze the precision, recall and F1-score of the classifiers. The prediction models represent a simple, yet effective model to accurately classify the accuracy of the simulation process based on application-independent approach. We analyze the different combinations of simulation accuracy classes for each components and present a guideline for making decision on accuracy level of simulation independent of components. We apply the proposed method on 2008 Chino Hills earthquake data and synthetic and present the results.







